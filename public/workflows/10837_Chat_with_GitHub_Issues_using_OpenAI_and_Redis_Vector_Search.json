{
  "id": "qfv7oKIaivIAdXJf",
  "meta": {
    "name": "Chat with GitHub Issues using OpenAI and Redis Vector Search",
    "id": 10837
  },
  "name": "AI agent with retrieval-augmented generation using a Redis vector store",
  "tags": [],
  "nodes": [
    {
      "id": "7c2856a9-5487-4fa2-aaa8-27730b91d1a6",
      "name": "When clicking ‘Execute workflow’",
      "type": "n8n-nodes-base.manualTrigger",
      "position": [
        64,
        736
      ],
      "parameters": {},
      "typeVersion": 1
    },
    {
      "id": "9dc70257-42ec-43e9-99bf-78b9173bb0c9",
      "name": "Embeddings OpenAI",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "position": [
        528,
        944
      ],
      "parameters": {
        "options": {}
      },
      "typeVersion": 1.2
    },
    {
      "id": "b7bfb31e-057e-434c-b6ea-89f70e8d1c9e",
      "name": "Default Data Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "position": [
        768,
        944
      ],
      "parameters": {
        "options": {
          "metadata": {
            "metadataValues": [
              {
                "name": "url",
                "value": "={{ $json.url }}"
              },
              {
                "name": "state",
                "value": "={{ $json.state }}"
              }
            ]
          }
        },
        "jsonData": "={\n title: '{{ $json.title }}',\n details: '{{ $json.body }}'\n}",
        "jsonMode": "expressionData"
      },
      "typeVersion": 1.1
    },
    {
      "id": "89a686e3-dd9d-43be-b5b9-f4412096295d",
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "position": [
        64,
        1328
      ],
      "webhookId": "db108354-b024-4ff8-98e3-6aa03d349d61",
      "parameters": {
        "public": true,
        "options": {}
      },
      "typeVersion": 1.4
    },
    {
      "id": "1760c33a-c541-4f93-8715-a89e0d99d303",
      "name": "OpenAI Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "position": [
        96,
        1536
      ],
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4.1-mini"
        },
        "options": {},
        "builtInTools": {}
      },
      "typeVersion": 1.3
    },
    {
      "id": "6105777c-9f2e-413f-9fcd-f3ef48bc2adf",
      "name": "Redis Chat Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryRedisChat",
      "position": [
        288,
        1536
      ],
      "parameters": {},
      "typeVersion": 1.5
    },
    {
      "id": "76d85316-db73-4829-849d-134785f96b6e",
      "name": "Embeddings OpenAI1",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "position": [
        560,
        1696
      ],
      "parameters": {
        "options": {}
      },
      "typeVersion": 1.2
    },
    {
      "id": "24920f0d-25c5-4e3e-994e-813134411b97",
      "name": "Sticky Note6",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -64,
        576
      ],
      "parameters": {
        "color": 7,
        "width": 1000,
        "height": 540,
        "content": "## 1. Data Ingestion Workflow\n[Read more about the Redis Vector Store node](https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstoreredis/)\n\nMake sure you replace the URL in the ```Fetch all issues from GitHub``` node with the URL to your repository"
      },
      "typeVersion": 1
    },
    {
      "id": "9e6a5465-6ab7-4109-b73e-5a1e1940cc17",
      "name": "Sticky Note7",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -672,
        576
      ],
      "parameters": {
        "width": 460,
        "height": 1088,
        "content": "## Try It Out!\n### This n8n template creates a Retrieval-Augmented Generation (RAG) system for exploring GitHub repository issues.\n\n### How It Works\nFirst, run the ingestion flow to populate the vector database with GitHub issues. Then, users can chat with the AI agent to explore issues using natural language queries. The agent searches the vector database to find relevant issues and provides informed responses based on actual repository data.\n\n### Part 1: Data Ingestion (Top Flow)\n**Manual Trigger → HTTP Request → Redis Vector Store**\n\n1. **Fetch Issues**: Makes an HTTP request to [GitHub API](https://docs.github.com/en/rest/issues/issues?apiVersion=2022-11-28) to retrieve all issues from the `{owner}/{repository}` repository\n2. **Process & Embed**: Extracts title and body from each issue, adds metadata (URL, state), and generates embeddings using OpenAI\n3. **Store in Redis**: Saves the embedded issue data into a Redis vector database (index: `github_issues_v1`) for semantic search\n\n### Part 2: Chat Interface (Bottom Flow)\n**Chat Trigger → AI Agent → Vector Search Tool**\n\n1. **Chat Interface**: Provides a public chat interface for users to ask questions about repository issues\n2. **AI Agent**: Uses GPT-4.1-mini to understand queries and decide when to search the vector database\n3. **Vector Search Tool**: Retrieves relevant issues from Redis using semantic similarity\n4. **Chat Memory**: Maintains conversation context in Redis for multi-turn interactions\n\n### Requirements\n* OpenAI account for LLM  generation\n* Redis server 8.x (for older versions you will need to also have the Redis Query Engine module installed)\n\n\n### Need Help?\nJoin us at [Discord](https://discord.com/invite/redis) and ask away!\n\nHappy Hacking!"
      },
      "typeVersion": 1
    },
    {
      "id": "6d69e1bf-aa29-478c-8f54-ed5a3808b38a",
      "name": "Sticky Note8",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -672,
        1696
      ],
      "parameters": {
        "color": 5,
        "width": 460,
        "height": 140,
        "content": "### GitHub Rate Limits\nUnauthenticated access to the GitHub REST API is imposed with the strictest [rate limits](https://docs.github.com/en/rest/using-the-rest-api/rate-limits-for-the-rest-api?apiVersion=2022-11-28). To improve ingestion speed you might want to configure a [personal access token](https://docs.github.com/en/rest/using-the-rest-api/rate-limits-for-the-rest-api?apiVersion=2022-11-28) in the ```Fetch all issues from GitHub``` step."
      },
      "typeVersion": 1
    },
    {
      "id": "26c500fc-5491-45bc-a107-76cdf65af64e",
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -64,
        1168
      ],
      "parameters": {
        "color": 7,
        "width": 1000,
        "height": 668,
        "content": "## 2. Chat Interface Workflow\n[Read more about the Redis Chat Memory node](https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memoryredischat/)\n\nThe same vector store and embeddings provider (as the one in the previous step) should be used for the flow to work correctly"
      },
      "typeVersion": 1
    },
    {
      "id": "19efedc2-c85a-4434-bf9f-7944db9cb351",
      "name": "Fetch issues from GitHub",
      "type": "n8n-nodes-base.httpRequest",
      "position": [
        352,
        736
      ],
      "parameters": {
        "url": "=https://api.github.com/repos/{{ $parameter.owner }}/{{ $parameter.repository }}/issues?per_page=100&state=open",
        "options": {
          "timeout": 1000,
          "response": {
            "response": {
              "fullResponse": true
            }
          },
          "pagination": {
            "pagination": {
              "nextURL": "={{ $response.headers['link'].split(';')[0].slice(1, -1); }}",
              "paginationMode": "responseContainsNextURL"
            }
          }
        }
      },
      "typeVersion": 4.2
    },
    {
      "id": "fde8b45c-5f20-4fff-a231-cf5459c30160",
      "name": "Vectorize and store in Redis",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreRedis",
      "position": [
        624,
        736
      ],
      "parameters": {
        "mode": "insert",
        "options": {},
        "redisIndex": {
          "__rl": true,
          "mode": "id",
          "value": "github_issues_v1"
        }
      },
      "typeVersion": 1.3
    },
    {
      "id": "89f97818-1bb9-4cb6-8f42-8936bcc2217d",
      "name": "AI Agent using RAG",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "position": [
        320,
        1328
      ],
      "parameters": {
        "options": {
          "maxIterations": 10,
          "systemMessage": "You are a helpful assistant for exploring a public GitHub repository. You have a vector search capability to locate explore existing issues in the repository, Use this capability effectively to provide accurate, relevant insights — avoid making assumptions or fabricating information."
        }
      },
      "typeVersion": 3
    },
    {
      "id": "d5b62fcf-0b06-4487-98fc-f97844753eb5",
      "name": "Augment with results from Redis",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreRedis",
      "position": [
        464,
        1536
      ],
      "parameters": {
        "mode": "retrieve-as-tool",
        "options": {},
        "redisIndex": {
          "__rl": true,
          "mode": "list",
          "value": "github_issues_v1",
          "cachedResultName": "github_issues_v1"
        },
        "toolDescription": "The list of issues from the database"
      },
      "typeVersion": 1.3
    }
  ],
  "active": false,
  "pinData": {},
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "a91089aa-f139-4c37-94e6-fd9a69203d23",
  "connections": {
    "Embeddings OpenAI": {
      "ai_embedding": [
        [
          {
            "node": "Vectorize and store in Redis",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "AI Agent using RAG",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Redis Chat Memory": {
      "ai_memory": [
        [
          {
            "node": "AI Agent using RAG",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "Embeddings OpenAI1": {
      "ai_embedding": [
        [
          {
            "node": "Augment with results from Redis",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "Default Data Loader": {
      "ai_document": [
        [
          {
            "node": "Vectorize and store in Redis",
            "type": "ai_document",
            "index": 0
          }
        ]
      ]
    },
    "Fetch issues from GitHub": {
      "main": [
        [
          {
            "node": "Vectorize and store in Redis",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "When chat message received": {
      "main": [
        [
          {
            "node": "AI Agent using RAG",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Augment with results from Redis": {
      "ai_tool": [
        [
          {
            "node": "AI Agent using RAG",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "When clicking ‘Execute workflow’": {
      "main": [
        [
          {
            "node": "Fetch issues from GitHub",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  }
}